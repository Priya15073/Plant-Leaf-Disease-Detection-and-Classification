# -*- coding: utf-8 -*-
"""InceptionV3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LpFBNbI-lrGqeruTonQ7lyE0FKn3ZgY_
"""

#Priya Rajpurohit 2015073
#Sakshi Saini 2017092

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
import os
import cv2
import numpy as np

from sklearn.model_selection import train_test_split
from keras.applications.inception_v3 import InceptionV3

from keras.layers import Conv2D, MaxPool2D,  \
    Dropout, Dense, Input, concatenate,      \
    GlobalAveragePooling2D, AveragePooling2D,\
    Flatten

from keras.models import Model
from keras.utils import np_utils
import matplotlib.pyplot as plt

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive1 = GoogleDrive(gauth)

link = 'https://drive.google.com/open?id=10fFInHmGZ5PsbMTRb_7EuhJcGNHisjCi'
fluff, id = link.split('=')
print (id)

downloaded = drive1.CreateFile({'id':id}) 
downloaded.GetContentFile('Segmented.zip')

from zipfile import ZipFile

with ZipFile('/content/Segmented.zip', 'r') as zipObj:
   zipObj.extractall()

path = '/content/Segmented/'
images=[]
labels=[]

lable = 1
for r, d, f in os.walk(path):
    for folder in d:       
        for r1, d1, f1 in os.walk(os.path.join(r, folder)):
          for file in f1:
            images.append( cv2.imread(os.path.join(r1, file) ))
            labels.append(lable)
          lable = lable +1

images = np.array(images)



X_train, X_test, y_train, y_test = train_test_split( images[:20000], labels[:20000], test_size=0.3, random_state=42 , shuffle=True)
print(X_train.shape, X_test.shape)

base_model = InceptionV3(weights='imagenet', include_top=False)

n = 38
x = base_model.output

x = GlobalAveragePooling2D(name='avg_pool')(x)
x = Dropout(0.4)(x)
predictions = Dense(n, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

y_train = np_utils.to_categorical( y_train, n)
y_test = np_utils.to_categorical( y_test, n)

EPOCHS = 20
BATCH_SIZE = 32

history = model.fit(
      X_train, y_train,
      epochs = EPOCHS,
      # steps_per_epoch = STEPS_PER_EPOCH,
      validation_data = (X_test, y_test ),
      # validation_steps = VALIDATION_STEPS,
      batch_size= 50,
      shuffle=True,
      verbose=1
    )

MODEL_FILE = 'inceptionV3Seg.model'
model.save(MODEL_FILE)

final_accuracy = history.history["val_accuracy"][-5:]
print("FINAL ACCURACY MEAN-5: ", np.mean(final_accuracy))

def display_training_curves(training, validation, title, subplot):
  ax = plt.subplot(subplot)
  ax.plot(training)
  ax.plot(validation)
  ax.set_title('InceptionV3 '+ title)
  ax.set_ylabel(title)
  ax.set_xlabel('epoch')
  ax.legend(['training', 'validation'])

plt.subplots(figsize=(10,10))
plt.tight_layout()
display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)
display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)







from keras.applications.inception_v3 import preprocess_input

model = InceptionV3(weights='imagenet', include_top=False)

fetaureX = []

for image in X_train:

  image = cv2.resize(image, (224, 224))

  image = np.expand_dims( image, axis=0)
  image = preprocess_input(image)
  feature = model.predict(image)

  fetaureX.append(feature)

fetaureXt = []

for image in X_test:

  image = cv2.resize(image, (224, 224))

  image = np.expand_dims(image, axis=0)
  image = preprocess_input(image)
  feature = model.predict(image)

  fetaureXt.append(feature)

from sklearn.ensemble import RandomForestClassifier

fetaureX = np.array(fetaureX)
fetaureX = fetaureX.reshape(14000, 51200)

clf = RandomForestClassifier()
clf.fit(fetaureX,  y_train)

featuresTest = np.array(fetaureXt)

featuresTest = featuresTest.reshape(6000, 51200)

accuracy = clf.score(featuresTest,y_test)
accuracy *= 100
print(accuracy)

import h5py


h5_data    = 'segmented_iception.h5'
h5_labels  = 'labels_inception_seg.h5'

h5f_data = h5py.File(h5_data, 'w')
h5f_data.create_dataset('dataset_1', data=np.array(fetaureX))

h5f_label = h5py.File(h5_labels, 'w')
h5f_label.create_dataset('dataset_1', data=np.array(y_train))

import h5py


h5_data    = 'segmented_iceptiontest.h5'
h5_labels  = 'labels_inception_segtest.h5'

h5f_data = h5py.File(h5_data, 'w')
h5f_data.create_dataset('dataset_1', data=np.array(featuresTest))

h5f_label = h5py.File(h5_labels, 'w')
h5f_label.create_dataset('dataset_1', data=np.array(y_test))

from sklearn import svm

featuresTrain = np.array(fetaureX)
featuresTrain = featuresTrain.reshape(14000, 51200)

clf1 = svm.SVC()
clf1.fit(featuresTrain,  y_train)

featuresTest = np.array(fetaureXt)

featuresTest = featuresTest.reshape(6000, 51200)

accuracy = clf1.score(featuresTest,y_test)
accuracy *= 100
print(accuracy)

filename = 'finalized_model.sav'
pickle.dump(clf1, open(filename, 'wb'))

2048*5*5

